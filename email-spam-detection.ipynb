{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3c870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba569a8",
   "metadata": {},
   "source": [
    "**Data Import & Snapshot of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9374212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data in a dataframe\n",
    "dt = pd.read_csv('SPAM-210331-134237.csv')\n",
    "\n",
    "# Snapshot of the data - 10 items\n",
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b4eb6a",
   "metadata": {},
   "source": [
    "**Mapping**\n",
    "\n",
    "Map the class 'spam' to 1 (int) and 'ham' to 0 (int)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9a990e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1   ham                      Ok lar... Joking wif u oni...     0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3   ham  U dun say so early hor... U c already then say...     0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization: Mapping 'spam' to 1 (int) and 'ham' to 0 (int)\n",
    "dt['spam'] = dt['type'].map({'spam':1, 'ham':0}).astype(int)\n",
    "\n",
    "dt.head() # Snapshot of updated dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7320050",
   "metadata": {},
   "source": [
    "List the names of columns in the updated datafram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "637818d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the given data:\n",
      "type\n",
      "text\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "print('Columns in the given data:')\n",
    "for col in dt.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b158a546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the review column: 116\n",
      "Number of rows in the liked column: 116\n"
     ]
    }
   ],
   "source": [
    "type_len = len(dt['type'])\n",
    "print('Number of rows in the review column:', type_len)\n",
    "\n",
    "text_len = len(dt['text'])\n",
    "print('Number of rows in the liked column:', text_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22193872",
   "metadata": {},
   "source": [
    "## 2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438644e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][1] # before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2ab957",
   "metadata": {},
   "source": [
    "**Tokenization**\n",
    "\n",
    "Tokenization is changing a sentence or multiple sentences into a bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52de5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24fa4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text'] = dt['text'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a69b709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ok', 'lar...', 'Joking', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][1] # after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c5470",
   "metadata": {},
   "source": [
    "**Stemming**\n",
    "\n",
    "Stemming is reducing all the derived words to their base words. For e.g., changing growing, grown, etc. to 'grow'.\n",
    "\n",
    "We can anyone of the three different tools:\n",
    "1. Snowball\n",
    "1. Porter\n",
    "1. Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b176b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yeah',\n",
       " 'hopefully,',\n",
       " 'if',\n",
       " 'tyler',\n",
       " \"can't\",\n",
       " 'do',\n",
       " 'it',\n",
       " 'I',\n",
       " 'could',\n",
       " 'maybe',\n",
       " 'ask',\n",
       " 'around',\n",
       " 'a',\n",
       " 'bit']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][48] # before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25f4a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "porter = SnowballStemmer('english', ignore_stopwords = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4d1635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_it(text):\n",
    "    \"\"\"Assumes text to be a list of strings.\n",
    "       Returns --> a list of strings of the same size\n",
    "       but having the words replaced by their respective\n",
    "       root forms.\"\"\"\n",
    "    return [porter.stem(word) for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e04b6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text'] = dt['text'].apply(stem_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ad94755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yeah',\n",
       " 'hopefully,',\n",
       " 'if',\n",
       " 'tyler',\n",
       " \"can't\",\n",
       " 'do',\n",
       " 'it',\n",
       " 'i',\n",
       " 'could',\n",
       " 'mayb',\n",
       " 'ask',\n",
       " 'around',\n",
       " 'a',\n",
       " 'bit']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][48] # after stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000be4e6",
   "metadata": {},
   "source": [
    "**Lemmitization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be1bffef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smile',\n",
       " 'in',\n",
       " 'pleasur',\n",
       " 'smile',\n",
       " 'in',\n",
       " 'pain',\n",
       " 'smile',\n",
       " 'when',\n",
       " 'troubl',\n",
       " 'pour',\n",
       " 'like',\n",
       " 'rain',\n",
       " 'smile',\n",
       " 'when',\n",
       " 'sum1',\n",
       " 'hurt',\n",
       " 'u',\n",
       " 'smile',\n",
       " 'becoz',\n",
       " 'someon',\n",
       " 'still',\n",
       " 'love',\n",
       " 'to',\n",
       " 'see',\n",
       " 'u',\n",
       " 'smiling!!']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][92] # before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32f63a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dca8854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_it(text):\n",
    "    return [lemmatizer.lemmatize(word, pos = 'a') for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "588dcb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text'] = dt['text'].apply(lemmatize_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff458b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smile',\n",
       " 'in',\n",
       " 'pleasur',\n",
       " 'smile',\n",
       " 'in',\n",
       " 'pain',\n",
       " 'smile',\n",
       " 'when',\n",
       " 'troubl',\n",
       " 'pour',\n",
       " 'like',\n",
       " 'rain',\n",
       " 'smile',\n",
       " 'when',\n",
       " 'sum1',\n",
       " 'hurt',\n",
       " 'u',\n",
       " 'smile',\n",
       " 'becoz',\n",
       " 'someon',\n",
       " 'still',\n",
       " 'love',\n",
       " 'to',\n",
       " 'see',\n",
       " 'u',\n",
       " 'smiling!!']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][92] # after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f87b05a",
   "metadata": {},
   "source": [
    "**Stopword Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82035456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank',\n",
       " 'for',\n",
       " 'your',\n",
       " 'subscript',\n",
       " 'to',\n",
       " 'rington',\n",
       " 'uk',\n",
       " 'your',\n",
       " 'mobil',\n",
       " 'will',\n",
       " 'be',\n",
       " 'charg',\n",
       " '£5/month',\n",
       " 'pleas',\n",
       " 'confirm',\n",
       " 'by',\n",
       " 'repli',\n",
       " 'yes',\n",
       " 'or',\n",
       " 'no.',\n",
       " 'if',\n",
       " 'you',\n",
       " 'repli',\n",
       " 'no',\n",
       " 'you',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'charg']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][34] # before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46a47f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b79fab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_it(text):\n",
    "    review = [word for word in text if not word in stop_words]\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49b41403",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text'] = dt['text'].apply(stop_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adc1e039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank',\n",
       " 'subscript',\n",
       " 'rington',\n",
       " 'uk',\n",
       " 'mobil',\n",
       " 'charg',\n",
       " '£5/month',\n",
       " 'pleas',\n",
       " 'confirm',\n",
       " 'repli',\n",
       " 'yes',\n",
       " 'no.',\n",
       " 'repli',\n",
       " 'charg']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][34] # after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4919b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point, crazy.. avail onli bugi n gre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joke wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkts 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say earli hor... u c alreadi say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think goe usf, live around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey darl 3 week word back! i'd like fu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even brother like speak me. treat like aid pat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>per request mell mell (oru minnaminungint nuru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner!! valu network custom select receivea £...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>mobil 11 month more? u r entitl updat late col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  go jurong point, crazy.. avail onli bugi n gre...     0\n",
       "1   ham                        ok lar... joke wif u oni...     0\n",
       "2  spam  free entri 2 wkli comp win fa cup final tkts 2...     1\n",
       "3   ham          u dun say earli hor... u c alreadi say...     0\n",
       "4   ham              nah think goe usf, live around though     0\n",
       "5  spam  freemsg hey darl 3 week word back! i'd like fu...     1\n",
       "6   ham  even brother like speak me. treat like aid pat...     0\n",
       "7   ham  per request mell mell (oru minnaminungint nuru...     0\n",
       "8  spam  winner!! valu network custom select receivea £...     1\n",
       "9  spam  mobil 11 month more? u r entitl updat late col...     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'] = dt['text'].apply(' '.join)\n",
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae860bf",
   "metadata": {},
   "source": [
    "**Vectorization**\n",
    "\n",
    "It is the process of changing the sentence (a string) to an array of numbers. The resulting vector should incorporate the frequency and significance of a word in a document.\n",
    "To vectorize a document, we use here, _**Term Frequency - Inverse Document Frequency (TF-IDF)**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31c51739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "y = dt.spam.values\n",
    "x = tfidf.fit_transform(dt['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d6589ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<116x709 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1076 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d93f150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbdb17c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320d0d7f",
   "metadata": {},
   "source": [
    "**Split the data into two categories: train-test spit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35f2c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "467868e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in train split: 92 \n",
      "Items in test split: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Items in train split:\", len(y_train), \"\\nItems in test split:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3398b2",
   "metadata": {},
   "source": [
    "**Classification using Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "846ccbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72ba7b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_log = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy:\", acc_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07776982",
   "metadata": {},
   "source": [
    "**Classification using LinearSVC Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15a46113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svc = LinearSVC(random_state = 0)\n",
    "linear_svc.fit(x_train, y_train)\n",
    "y_pred = linear_svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38a3e458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.5\n"
     ]
    }
   ],
   "source": [
    "acc_linear_svc = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy:\", acc_linear_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3bc5be",
   "metadata": {},
   "source": [
    "Looks like both **Logistic Regression** and the **Linear Regression** both models have the same accuracy %. And the accuracy of 87.5% is not really that great, but considering the small dataset of just 116 observation, it is good enough!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
